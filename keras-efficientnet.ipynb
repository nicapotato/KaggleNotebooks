{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Cassava Leaf Disease Classification:"},{"metadata":{},"cell_type":"markdown","source":"## Loading packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.optimizers import Adam\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\nfrom PIL import Image\nfrom random import randint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"# File Parameters\nWORK_DIR = \"../input/humpback-whale-identification\"\nlabel_col = \"Id\"\nimg_col = \"Image\"\ntrain_folder = \"train\"\ntest_folder = \"test\"\n\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First look at the data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, train_folder))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\nlabel_names = train_labels[label_col].value_counts().index\nlabel_map = {name:i for (i,name) in enumerate(label_names)}\ninv_label_map = {v: k for k, v in label_map.items()}\n\ntrain_labels['label_name'] = train_labels[label_col].copy()\ntrain_labels[label_col] = train_labels[label_col].map(label_map)\ndisplay(train_labels.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main parameters\nBATCH_SIZE = 8\nSTEPS_PER_EPOCH = len(train_labels)*0.8 / BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.2 / BATCH_SIZE\nEPOCHS = 4\nTARGET_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize = (6, 4))\n\nfor i in ['top', 'right', 'left']:\n    ax.spines[i].set_visible(False)\nax.spines['bottom'].set_color('black')\n\nsns.countplot(y = train_labels[\"label_name\"], order=train_labels[\"label_name\"].value_counts().index[:5], edgecolor = 'black',\n              palette = reversed(sns.color_palette(\"viridis\", 5)))\nplt.xlabel('Classes', fontfamily = 'serif', size = 15)\nplt.ylabel('Count', fontfamily = 'serif', size = 15)\nplt.xticks(fontfamily = 'serif', size = 12)\nplt.yticks(fontfamily = 'serif', size = 12)\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_plot(df, label=None):\n    if label:\n        sample = df[df[\"label_name\"] == label].sample(3)\n        folder = train_folder\n    else:\n        sample = df.sample(3)\n        sample[\"label_name\"] = \"test\"\n        folder = test_folder\n    plt.figure(figsize=(15, 5))\n    for ind, (image_id, label) in enumerate(zip(sample[img_col], sample[\"label_name\"])):\n        plt.subplot(1, 3, ind + 1)\n        img = cv2.imread(os.path.join(WORK_DIR, folder, image_id))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.title(\"Label: {}\\nShape: {}\".format(label, img.shape))\n        plt.imshow(img)\n        plt.axis(\"off\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for lbl in label_names[:3]:\n    img_plot(train_labels, lbl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparation for modeling"},{"metadata":{},"cell_type":"markdown","source":"### ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     rotation_range = 45,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.1,\n                                     height_shift_range = 0.1,\n                                     width_shift_range = 0.1)\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, train_folder),\n                         subset = \"training\",\n                         x_col = img_col,\n                         y_col = label_col,\n                         color_mode='grayscale',\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"raw\")\n\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.2)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, train_folder),\n                         subset = \"validation\",\n                         color_mode='grayscale',\n                         x_col = img_col,\n                         y_col = label_col,\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"raw\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_from_generator(train_generator, label_names, n=5):\n    for _ in range(n):\n        batch_num = randint(0, len(train_generator))\n        bach_element = randint(0, BATCH_SIZE-1)\n\n        batch = train_generator[batch_num]\n        aug_images = [i/ 255 for i in batch[0]]\n        aug_labels = list(batch[1])\n\n        fig, axes = plt.subplots(1, 5, figsize = (20, 10))\n        axes = axes.flatten()\n        for img, lbl, ax in zip(aug_images, aug_labels, axes):\n            img = np.squeeze(img)\n            ax.imshow(img)\n            ax.set_title(lbl)\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_from_generator(train_generator, label_names, n=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    conv_base = EfficientNetB0(include_top = False, weights = None,\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 1))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dense(len(label_names)+1, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"acc\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Our EfficientNet CNN has %d layers' %len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.load_weights('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model_name = './EffNetB0_512_8_best_weights.h5'\nmodel_save = ModelCheckpoint(model_name, \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(model_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of CNN intermediate activations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def activation_layer_vis(img, activation_layer = 0, layers = 10):\n    layer_outputs = [layer.output for layer in model.layers[:layers]]\n    activation_model = models.Model(inputs = model.input, outputs = layer_outputs)\n    activations = activation_model.predict(img)\n    fig, axes = plt.subplots(1, 1, figsize = (5, 5))\n    axes.matshow(np.squeeze(activations[activation_layer][0, :, :, :]), cmap = 'viridis')\n    axes.axis('off')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization of the first layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_tensor = validation_generator[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activation_layer_vis(img_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def all_activations_vis(img, layers = 10):\n    layer_outputs = [layer.output for layer in model.layers[:layers]]\n    activation_model = models.Model(inputs = model.input, outputs = layer_outputs)\n    activations = activation_model.predict(img)\n    \n    layer_names = []\n    for layer in model.layers[:layers]: \n        layer_names.append(layer.name) \n\n    \n    images_per_row = 5\n    rows = np.ceil(13 / 5)\n    \n    plt.figure(figsize=(images_per_row*5, rows*5))\n    i = 0\n    for (layer_name, layer_activation) in zip(layer_names, activations): \n        n_features = layer_activation.shape[-1]\n\n        size = layer_activation.shape[1]\n        channel_image = np.squeeze(layer_activation[0, :, :, 0]) \n        channel_image -= channel_image.mean() \n        channel_image /= channel_image.std() \n        channel_image *= 64 \n        channel_image += 128 \n        channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n        \n        plt.subplot(rows, images_per_row, i + 1)\n        plt.imshow(channel_image)\n        \n        plt.title(layer_name) \n        plt.grid(False)\n        plt.axis('off')\n        \n        i += 1\n    plt.tight_layout(pad=.5)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization of the first 5 layers"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_activations_vis(img_tensor, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualization of intermediate activations gives a rough step-by-step understanding of how CNN works."},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lbl in label_names[:3]:\n    img_plot(ss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ntop_n = 5\nfor image_id in ss[img_col]:\n    image = Image.open(os.path.join(WORK_DIR, test_folder, image_id)).convert('L')\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    arr = model.predict(image)[0].argsort()[-top_n:][::-1]\n    p = \" \".join(np.vectorize(inv_label_map.get)(arr))\n    preds.append(p)\nss[label_col] = preds\nss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index = False)\nprint(ss.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}