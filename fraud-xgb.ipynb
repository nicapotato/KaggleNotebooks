{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fraud XGB"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/arnocandel/python-datatable\n# more information: http://github.com/h2oai/datatable\n!pip install --upgrade https://s3.amazonaws.com/artifacts.h2o.ai/releases/ai/h2o/pydatatable/0.8.0.dev115/x86_64-centos7/datatable-0.8.0.dev115-cp36-cp36m-linux_x86_64.whl\n    \n# Latest Pandas version\n!pip install -q 'pandas==0.25' --force-reinstall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datatable as dt\nimport pandas as pd\nprint(\"DataTable version:\", dt.__version__)\nprint(\"Pandas version:\", pd.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport time\nnotebookstart = time.time()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nfrom contextlib import contextmanager\nimport gc; gc.enable()\nimport pprint\nimport time\n\nimport datetime\nimport csv\nimport random\n\nfrom sklearn import preprocessing\n\n# Viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Modeling\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n\nimport eli5\nimport xgboost as xgb\nprint(\"XGB version:\", xgb.__version__)\n\nseed = 24\nnp.random.seed(seed)\n\npd.set_option('display.max_columns', 500)\npd.options.display.max_rows = 999\npd.set_option('max_colwidth', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Drop Cols..\")\nimportant_cols = ['R_emaildomain_suffix','V1','V10','V100','V101',\n'V102','V103','V104','V105','V106','V108','V109','V11','V110','V111','V112','V113','V114','V115','V116','V118','V12','V120',\n'V121','V122','V123','V124','V125','V13','V135','V137','V139','V140','V142','V143','V144','V145','V146','V148','V149','V150',\n'V151','V152','V153','V154','V155','V156','V157','V158','V159','V160','V161','V162','V164','V165','V166','V167','V168','V169',\n'V17','V170','V171','V172','V173','V174','V175','V176','V177','V178','V179','V18','V180','V182','V183','V184','V185','V187',\n'V188','V189','V190','V191','V192','V194','V195','V199','V2','V200','V201','V202','V203','V204','V205','V206','V207','V208',\n'V21','V210','V211','V212','V213','V214','V215','V216','V217','V218','V219','V220','V221','V222','V223','V224','V225','V226',\n'V227','V228','V229','V230','V231','V232','V233','V234','V236','V237','V238','V239','V24','V242','V243','V244','V245','V246',\n'V247','V248','V249','V25','V250','V251','V252','V253','V254','V255','V256','V257','V259','V26','V260','V261','V262','V263',\n'V264','V265','V266','V267','V268','V270','V271','V272','V273','V274','V275','V276','V277','V278','V279','V280','V284','V286',\n'V287','V288','V289','V29','V290','V291','V292','V293','V295','V297','V298','V299','V3','V30','V300','V301''V303','V304',\n'V319','V32','V322','V323','V324','V326','V327','V33','V331','V332','V333','V335','V336','V337','V338','V339','V34','V37',\n'V39','V4','V40','V41','V42','V43','V44','V46','V48','V49','V50','V51''V52','V55','V57','V58','V59','V6','V60','V63','V64',\n'V66','V67','V69','V7','V70','V71','V72','V73','V74','V75','V76','V77','V79','V8','V80','V81','V84','V85','V9','V90','V91',\n'V93','V94','V95','V97','V98',\n'distgroup_0_count','distgroup_nan_sum','id_03','id_04','id_07','id_08','id_09','id_10','id_11','id_12','id_15','id_16',\n'id_17','id_21','id_22','id_23','id_25','id_26','id_28','id_29','id_32','id_34','id_35','id_36','id_37','id_38',\n'idgroup_nan_sum']\n\ndrop_more = ['C8_AMT_12h_mean', 'card4_AMT_5d_sum', 'idgroup_mean',\n       'idgroup_sum', 'C8_AMT_5d_count', 'C8_AMT_12h_count',\n       'C1_AMT_12h_mean', 'C7_AMT_12h_sum', 'C8_AMT_5d_mean',\n       'C3_AMT_5d_mean', 'C6_AMT_5d_count', 'C1_AMT_12h_count',\n       'C7_AMT_5d_count', 'id_02_to_std_card4', 'C12_AMT_5d_count',\n       'C14_AMT_12h_sum', 'card4_AMT_5d_count', 'C10_AMT_5d_mean',\n       'card6_AMT_12h_count', 'C11_AMT_5d_count', 'Transactiongroup_sum',\n       'card6_AMT_12h_sum', 'D5', 'DeviceInfo', 'id_02', 'C8_AMT_12h_sum',\n       'C6_AMT_12h_sum', 'C12', 'id_02_to_std_card1', 'Dgroup_nan_sum',\n       'C4_AMT_5d_sum', 'C7_AMT_12h_mean', 'card2_AMT_12h_mean', 'V45',\n       'V83', 'id_02_to_mean_card4', 'V96', 'V328', 'C11_AMT_12h_sum',\n       'C9_AMT_12h_mean', 'V78', 'C4_AMT_12h_mean', 'V119',\n       'C3_AMT_12h_mean', 'V129', 'V283', 'card3_AMT_5d_count', 'D9',\n       'V134']\n\ndrop = ['level_0', 'index', 'month', 'year',\n        'TransactionDT', 'day', 'isFraud2'] + important_cols  + drop_more","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path1 = '../input/ieee-fraud-detection/'\nfolder_path2 = '../input/ieee-fraud-feature-engineering-and-eda/'\n\n\n\ndef reduce_mem_usage(df, verbose=True):\n    print(\"\\nMemeory Usage Before:\")\n    print(df.info(memory_usage = 'deep'))\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    \n    print(\"Memeory Usage After:\")\n    print(df.info(memory_usage = 'deep'))\n    return df\n\n@contextmanager\ndef timer(name):\n    \"\"\"\n    Time Each Process\n    \"\"\"\n    t0 = time.time()\n    yield\n    print('\\n[{}] done in {} Minutes'.format(name, round((time.time() - t0)/60,2)))\n\ndef fe_read(table):        \n    with timer(\"Read {}\".format(table)):\n        df_transaction = dt.fread(f'{folder_path1}{table}_transaction.csv')\n        df_identity = dt.fread(f'{folder_path1}{table}_identity.csv')\n        df_identity.key = 'TransactionID'\n        df = df_transaction[:, :, dt.join(df_identity)]\n        df_fe = dt.fread(f'{folder_path2}{table}_fraud_fe_nb.csv')\n        df_fe.names = {'isFraud': 'isFraud2'}\n        df_fe.key = 'TransactionID'\n        df_out = df[:, :, dt.join(df_fe)]\n        \n        keepcols = [x for x in df_out.names if x not in drop]\n        \n    return df_out[:,keepcols]\n\ndef fraud_process(important_cols):\n    with timer(\"Fraud Pre-Process\"):\n        with timer(\"Concat\"):            \n            tr_df = fe_read(table= 'train').to_pandas()\n            te_df = fe_read(table= 'test').to_pandas()\n            \n            df = pd.concat([tr_df, te_df],\n                           axis = 0, sort = True).reset_index()\n            df.set_index('TransactionID', inplace=True)\n            print(df.shape)\n\n        with timer(\"Label Encode\"):\n            categorical_cols = []\n            # Label Encoding\n            for f in [x for x in df.columns if x is not 'isFraud']:\n                if df[f].dtype=='object': \n                    categorical_cols += [f]\n                    lbl = preprocessing.LabelEncoder()\n                    df[f] = lbl.fit_transform(df[f].fillna(-9).astype(str))\n\n        with timer(\"Reduce Memory\"):\n            df = reduce_mem_usage(df)\n\n        df.loc[df.isFraud == 0, 'isFraud'] = np.nan\n        print(df.shape)\n        print(df.isFraud.value_counts())\n\n        train = df.loc[df.isFraud.notnull(), :].fillna(-9)\n        y = df.loc[df.isFraud.notnull(), 'isFraud'].copy() - 1\n        test = df.loc[df.isFraud.isnull(), :].fillna(-9)\n\n        train.drop('isFraud', axis = 1, inplace=True)\n        test.drop('isFraud', axis = 1, inplace=True)\n\n        feature_subset = train.columns\n\n        split_size = 0.25\n        X_train, X_valid, y_train, y_valid = train_test_split(\n            train[feature_subset], y, test_size=split_size,\n            random_state=seed, shuffle=False)\n        del train; gc.collect()\n        # XGBOOST Efficient Feature Storage\n        d_train = xgb.DMatrix(X_train, y_train,feature_names=feature_subset)\n        del X_train ;gc.collect()\n        d_valid = xgb.DMatrix(X_valid, y_valid,feature_names=feature_subset)\n        d_test = xgb.DMatrix(test,feature_names=feature_subset)\n\n    return d_train, d_valid, d_test, X_valid.values, y_valid.values, categorical_cols, feature_subset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Data\nd_train, d_valid, d_test, X_valid, y_valid, categorical_cols, feature_subset = fraud_process(important_cols = important_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = 10000\nmetric = 'auc'\nESR = 500\n\nparams = {\n     'colsample_bytree': 0.5317364823333394,\n     'eval_metric': metric,\n     'importance_type': 'weight',\n     'learning_rate': 0.08,\n     'max_depth': 9,\n     'missing': -9,\n#      'num_boost_round': 100,\n     'objective': 'binary:logistic',\n     'reg_alpha': 0.05,\n     'reg_lambda': 0.1749522739788873,\n     'seed': 24,\n     'subsample': 0.8}\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nmodel = xgb.train(params = params,\n                  dtrain = d_train,\n                  num_boost_round = n_estimators,\n                  evals = watchlist,\n                  verbose_eval=500,\n                  early_stopping_rounds=ESR)\ndel d_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer(\"Predict / Submission\"):\n    sample_submission = pd.read_csv(f'{folder_path1}sample_submission.csv', index_col='TransactionID')\n    sample_submission['isFraud'] = model.predict(d_test)\n    sample_submission.to_csv('xgboost_starter.csv')\n    \n    del d_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = [10,20])\nxgb.plot_importance(model, max_num_features  = 100, ax = ax)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_imp = pd.DataFrame.from_dict(model.get_score(), orient='index')\\\n    .rename(columns = {0: 'importance'})\\\n    .sort_values(by = \"importance\", ascending = False)\nf_imp.to_csv(\"Feature_importance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(f_imp)\nplt.title(\"Importance Distribution\")\nplt.show()\n\nprint(f_imp.loc[f_imp.importance < 25,'importance'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nt1 = xgb.DMatrix(X_valid,feature_names=feature_subset)\ndel t1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"permutation_iter = 1\n\n# feature permutation\n# ... load data, define score function\ndef score(X, y):\n    val_pred = model.predict(xgb.DMatrix(X,feature_names=feature_subset))\n    return roc_auc_score(y, val_pred)\nwith timer(\"Permutation Importance\"):\n    base_score, score_decreases = eli5.permutation_importance.get_score_importances(\n                                                        score_func = score,\n                                                        X = X_valid,\n                                                        y = y_valid,\n                                                        n_iter = permutation_iter,\n                                                        random_state = seed)\nfeature_importances = np.mean(score_decreases,axis=0)\n\n# To DF\nmodel_importance = pd.DataFrame()\nmodel_importance['feats'] = feature_subset\nmodel_importance['perm_score'] = np.mean(score_decreases, axis=0)\nmodel_importance['perm_std'] = np.std(score_decreases, axis=0)\nmodel_importance = model_importance.sort_values(by='perm_score', ascending=True)\ndisplay(model_importance.head(40))\n\nmodel_importance.to_csv(\"Permutation_importance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Notebook Runtime: %0.2f Hours\"%((time.time() - notebookstart)/60/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}