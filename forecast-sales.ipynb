{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"db6121b82f58e5547182afd131b1f115aedcc7fb"},"cell_type":"code","source":"## Forecast Sales","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nnotebookstart= time.time()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\n\n# Modeling\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nprint(\"Data Load Stage\")\ntraining = pd.read_csv('../input/train.csv', parse_dates = [\"date\"])#.sample(1000)\ntesting = pd.read_csv('../input/test.csv', parse_dates = [\"date\"])\ntestdex = testing.id\n\n# Merge\ndf = pd.concat([training,testing.drop(\"id\",axis=1)],axis=0, sort=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed9c7554a7ee571aa5ed88cf8c6f7b8cb2510a8"},"cell_type":"code","source":"def prepare_time_features(df):\n    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n    df['week'] = df.date.dt.week\n    df['month'] = df.date.dt.month\n    df['day_of_year'] = df.date.dt.dayofyear\n    df['week_of_year'] = df.date.dt.weekofyear\n    df[\"weekday\"] = df.date.dt.weekday\n    df[\"quarter\"] = df.date.dt.quarter\n    df[\"day_of_month\"] = df.date.dt.day\n    \n    return df\n\n# Time Feats\ndf = prepare_time_features(df)\n\n# Reshape\n# df = df.groupby([\"date\", \"store\",\"item\",]).sum().reset_index()\ntrain = df.loc[df.date < pd.to_datetime('2018-01-01')]\nprint(\"Train Shape: \", train.shape)\ntest_df = df.loc[df.date >= pd.to_datetime('2018-01-01')]\nprint(\"Test Shape: \", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1dd7f6002938389a41956d85b62fd3e39cc443d0"},"cell_type":"code","source":"# Time Aggregate Features\ndef percentile(n):\n    def percentile_(x):\n        return np.percentile(x, n)\n    percentile_.__name__ = 'percentile_%s' % n\n    return percentile_\n\n# Build\ndef time_agg(train, test_df, vars_to_agg, vars_be_agg):\n    for var in vars_to_agg:\n        if isinstance(var, list):\n            agg = train.groupby(var)[vars_be_agg].agg([\"sum\",\"mean\",\"std\",\"skew\",percentile(80),percentile(20)])\n            agg.columns = pd.Index([\"fare_by_\" + \"_\".join(var) + \"_\" + str(e) for e in agg.columns.tolist()])\n            train = pd.merge(train,agg, on=var, how= \"left\")\n            test_df = pd.merge(test_df,agg, on=var, how= \"left\")\n        else:\n            agg = train.groupby(var)[vars_be_agg].agg([\"sum\",\"mean\",\"std\",\"skew\",percentile(80),percentile(20)])\n            agg.columns = pd.Index([\"fare_by_\" + var + \"_\" + str(e) for e in agg.columns.tolist()])\n            train = pd.merge(train,agg, on=[var], how= \"left\")\n            test_df = pd.merge(test_df,agg, on=[var], how= \"left\")\n    \n    return train, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea0c370a0d77cd7c0b850c3e27c7521530535ca5"},"cell_type":"code","source":"%%time\n# Time Aggregate Features\ntrain, test_df = time_agg(train, test_df, vars_to_agg= \n                          [\"item\",\"store\",\"date\", [\"week\",\"item\",\"store\"], [\"month\",\"item\",\"store\"], [\"day_of_year\",\"item\",\"store\"], [\"weekday\",\"item\",\"store\"],\n                           [\"quarter\",\"item\",\"store\"], [\"day_of_month\",\"item\",\"store\"], [\"item\",\"store\",\"weekday\",\"month\"]], vars_be_agg = \"sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cabde72356dce3f688ec0448ffeaf2a172c27024"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3195a744d5bdfc683ecb74670012076a19f67e82"},"cell_type":"code","source":"# Keep Relevant Variables..\ny = train.sales.copy()\ntest_df.drop([\"date\", \"sales\"], axis = 1, inplace=True)\ntrain = train[test_df.columns]\nprint(\"Does Train feature equal test feature?: \", all(train.columns == test_df.columns))\ntrainshape = train.shape\ntestshape = test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"db0b91ccc075c3bcdebca461b44b49a4790eead8"},"cell_type":"code","source":"# LGBM Dataset Formating\ndtrain = lgb.Dataset(train, label=y, free_raw_data=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbff47334f0dc3cd2dccfa4cae3de82c6ced5672"},"cell_type":"code","source":"print(\"Light Gradient Boosting Regressor: \")\nlgbm_params =  {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': \"mape\"\n                }\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=1)\nfold_preds = np.zeros(testshape[0])\noof_preds = np.zeros(trainshape[0])\ndtrain.construct()\n\n# Fit 5 Folds\nmodelstart = time.time()\nfor trn_idx, val_idx in folds.split(train):\n    clf = lgb.train(\n        params=lgbm_params,\n        train_set=dtrain.subset(trn_idx),\n        valid_sets=dtrain.subset(val_idx),\n        # categorical_feature = [\"item\",\"store\"],\n        num_boost_round=5000, \n        early_stopping_rounds=125,\n        verbose_eval=500\n    )\n    oof_preds[val_idx] = clf.predict(dtrain.data.iloc[val_idx])\n    fold_preds += clf.predict(test_df) / folds.n_splits\n    print(\"RMSE: \", mean_squared_error(y.iloc[val_idx], oof_preds[val_idx]) ** .5)\nprint(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e6784a9aa7a86f6dcc724c172d0ce941fc9ea47"},"cell_type":"code","source":"lgsub = pd.DataFrame(fold_preds,columns=[\"sales\"],index=testdex)\nlgsub.to_csv(\"date.csv\",index=True,header=True)\n\nprint(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))\nlgsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}