{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport torch\nimport cv2\nimport torchvision\nfrom torchvision import transforms, datasets, models\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nfrom PIL import Image\nimport albumentations as albu\nimport albumentations.pytorch as pyalbu\nfrom torchsummary import summary\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nprint(\"Albumentations Version: {}\".format(albu.__version__))\nprint(\"Torch Version: {}\".format(torch.__version__))\n\nclass_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n\nraw_image_shape = (1400, 2100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/understanding_cloud_organization'\nos.listdir(path)\n\ntrain = pd.read_csv(f'{path}/train.csv')\nsub = pd.read_csv(f'{path}/sample_submission.csv')\n\nn_train = len(os.listdir(f'{path}/train_images'))\nn_test = len(os.listdir(f'{path}/test_images'))\nprint(f'There are {n_train} images in train dataset')\nprint(f'There are {n_test} images in test dataset')\n\ntrain['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n\n\nsub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\nsub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total Labels for each class\")\nprint(train.loc[train.label.notnull(),'label'].value_counts())\n\nprint(\"\\nOccurence of number of labels for each image\")\nprint(train.groupby(\"im_id\").count()['EncodedPixels'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n    '''\n    Decode rle encoded mask.\n    \n    :param mask_rle: run-length as string formatted (start length)\n    :param shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\ndef make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n    \"\"\"\n    Create mask based on df, image name and shape.\n    \"\"\"\n    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n\n    for idx, label in enumerate(encoded_masks.values):\n        if label is not np.nan:\n            mask = rle_decode(label)\n            masks[:, :, idx] = mask\n            \n    return masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 21))\nfor j, im_id in enumerate(np.random.choice(train['im_id'].unique(), 4)):\n    for i, (idx, row) in enumerate(train.loc[train['im_id'] == im_id].iterrows()):\n        ax = fig.add_subplot(5, 4, j * 4 + i + 1, xticks=[], yticks=[])\n        im = Image.open(f\"{path}/train_images/{row['Image_Label'].split('_')[0]}\")\n        plt.imshow(im)\n        mask_rle = row['EncodedPixels']\n        try: # label might not be there!\n            mask = rle_decode(mask_rle)\n        except Exception as e:\n            mask = np.zeros(raw_image_shape)\n#             print(e)\n        plt.imshow(mask, alpha=0.5, cmap='gray')\n        ax.set_title(f\"Image: {row['Image_Label'].split('_')[0]}. Label: {row['label']}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resize_shape = (320,640)\n# resize_shape = tuple([(x / 10) for x in raw_image_shape])\n\nprint(resize_shape)\n\n# Transformations for the train\ntrain_trans = albu.Compose([\n    albu.HorizontalFlip(),\n    albu.Resize(*resize_shape),\n    pyalbu.ToTensor()])\n\n# Transformations for the validation & test sets\nval_trans = albu.Compose([\n#     albu.HorizontalFlip(),\n    albu.Resize(*resize_shape),\n    pyalbu.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CloudDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transforms, datatype: str = 'train', img_ids: np.array = None):\n        self.df = df\n        if datatype != 'test':\n            self.data_folder = f\"{path}/train_images\"\n        else:\n            self.data_folder = f\"{path}/test_images\"\n        self.img_ids = img_ids\n        self.transforms = transforms\n\n    def __getitem__(self, idx):\n        image_name = self.img_ids[idx]\n        mask = make_mask(self.df, image_name)\n        image_path = os.path.join(self.data_folder, image_name)\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask']\n        mask = mask[0].permute(2, 0, 1)\n        return img, mask\n\n    def __len__(self):\n        return len(self.img_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Test Split\ntrain_img_split = train.loc[train.EncodedPixels.notnull(),'im_id'].value_counts().reset_index()\ntrain_images, val_images = train_test_split(train_img_split['index'],\n                                            stratify = train_img_split['im_id'],\n                                            test_size=0.2)\n\ntrain_data = CloudDataset(df = train,\n                          transforms = train_trans,\n                          datatype = 'train',\n                          img_ids = train_images.values\n                         )\n\nval_data = CloudDataset(df = train,\n                          transforms = val_trans,\n                          datatype = 'validation',\n                          img_ids = val_images.values\n                         )\n\nimage_datasets = {\n    'train': train_data, 'val': val_data\n}\n\nbatch_size = 8\nnum_workers = 0\n\ndataloaders = {\n    'train': torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers),\n    'val': torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = next(iter(train_data))\ninputshape = batch[0].size()\nprint(\"Input Shape: {}\\nOutput Shape: {}\".format(inputshape,batch[1].size()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = [25,18])\nnum_images = 6\nfor nth in range(1, num_images + 1):\n    batch = train_data[np.random.randint(len(train_data), size=1)[0]]\n    batch_image = batch[0].numpy().transpose((1,2,0))\n    batch_mask = batch[1].numpy()\n\n    ax = plt.subplot(num_images//2, 2, nth)\n    ax.axis('off')\n    ax.imshow(batch_image, cmap='gray', interpolation='none')\n    for i,color in enumerate(['prism', 'viridis', 'twilight', 'plasma']):\n        mask = batch_mask[i]\n        if (mask > 0).any():\n            masked = np.ma.masked_where(mask == 0, mask)\n            ax.imshow(masked, cmap=color, alpha=0.3)\n            \nplt.subplots_adjust(wspace=0.1, hspace=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, n_channels, n_classes, dropout):\n        super(Net, self).__init__()\n\n        self.convin = nn.Conv2d(in_channels=n_channels, out_channels=64, kernel_size=5, stride=1, padding=2)\n        self.convout = nn.Conv2d(64, n_classes, 1)\n        \n        \n    def forward(self, x):\n        x = self.convin(x)\n        x = F.relu(x)\n        x = self.convout(x)\n        return x\n\nnet = Net(n_channels=3, n_classes=4, dropout = .4).to(device)\nnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\n\ndef dice_loss(pred, target, smooth = 1.):\n    pred = pred.contiguous()\n    target = target.contiguous()    \n\n    intersection = (pred * target).sum(dim=2).sum(dim=2)\n    \n    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n    \n    return loss.mean()\n\ndef calc_loss(pred, target, metrics, bce_weight=0.5):\n    bce = F.binary_cross_entropy_with_logits(pred, target)\n        \n    pred = torch.sigmoid(pred)\n    dice = dice_loss(pred, target)\n    \n    loss = bce * bce_weight + dice * (1 - bce_weight)\n    \n    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n    \n    return loss\n\ndef print_metrics(metrics, epoch_samples, phase):    \n    outputs = []\n    for k in metrics.keys():\n        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n        \n    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n\ndef train_model(model, optimizer, scheduler, num_epochs=25):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 1e10\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        since = time.time()\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                for param_group in optimizer.param_groups:\n                    print(\"LR\", param_group['lr'])\n                    \n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            metrics = defaultdict(float)\n            epoch_samples = 0\n            \n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)    \n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = calc_loss(outputs, labels, metrics)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        scheduler.step()\n                # statistics\n                epoch_samples += inputs.size(0)\n\n            print_metrics(metrics, epoch_samples, phase)\n            epoch_loss = metrics['loss'] / epoch_samples\n\n            # deep copy the model\n            if phase == 'val' and epoch_loss < best_loss:\n                print(\"saving best model\")\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        time_elapsed = time.time() - since\n        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n            \n    print('Best val loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.cuda.empty_cache()\n\n# base_model = models.resnet18(pretrained=False)\n# list(base_model.children())\n\n# net = ResNetUNet(n_class = 4)\n# net = UNet(n_channels=3, n_classes=4).to(device)\nsummary(net, input_size=tuple(inputshape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom collections import defaultdict\nimport time\nimport copy\n\n# freeze backbone layers\n#for l in model.base_layers:\n#    for param in l.parameters():\n#        param.requires_grad = False\n\noptimizer = optim.Adam(net.parameters(), lr=0.1)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n\nmodel = train_model(net, optimizer, exp_lr_scheduler, num_epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}