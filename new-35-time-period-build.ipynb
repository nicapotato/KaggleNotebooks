{"cells":[{"metadata":{"_uuid":"3cdb3935a174ab10e90382f976c4123aa2bbeb6d","scrolled":false,"trusted":true},"cell_type":"code","source":"# Core\nimport time\nnotebookstart= time.time()\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Keras Neural Net / LSTM (RNN)\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers\n\n\n# Sklearn Support\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\nimport gc\n\n# Viz\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Utility\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n\n# IN_PATH = \"Large Data/Predict Future Sales/\"\n# OUT_PATH = \"Large Data/Predict Future Sales/\"\nIN_PATH = \"../input/\"\nOUT_PATH = \"\" \n# Import data\nsales = pd.read_csv(IN_PATH + 'sales_train.csv', parse_dates=['date'], infer_datetime_format=True, dayfirst=True)\nshops = pd.read_csv(IN_PATH + 'shops.csv')\nitems = pd.read_csv(IN_PATH + 'items.csv')\ncats = pd.read_csv(IN_PATH + 'item_categories.csv')\nval = pd.read_csv(IN_PATH + 'test.csv')\n#\"sample_submission.csv.gz\"\n\n# scaler = preprocessing.StandardScaler()\nscaler = MinMaxScaler(feature_range=(0, 1))\nsales[\"item_price\"] = scaler.fit_transform(sales[\"item_price\"].values.reshape(-1,1))\n# sales[\"item_cnt_day\"] = scaler.fit_transform(sales[\"item_cnt_day\"].values.reshape(-1,1))\n# sales[\"item_cnt_day\"] = sales[\"item_cnt_day\"].astype(int)\nsales[\"item_cnt_day\"].clip(0.,20.,inplace=True)\n\n# Remove the items/shops outside of forecast range\nsales = pd.merge(val,sales,on=['item_id','shop_id'], how='left')\nsales = sales.fillna(0)\n\n# Represents the submission set\nexpand = sales.loc[sales.date_block_num == 33,:]\nexpand.loc[:,\"date_block_num\"] = 34.0\nsales = pd.concat([sales,expand])","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"abe7e3c093468b1721284fc26393c498e8ba0c85","trusted":true,"collapsed":true},"cell_type":"code","source":"# Clean\ndf = (sales.groupby([\"date_block_num\",'shop_id',\"item_id\"])[[\"item_price\",\"item_cnt_day\"]].sum()\n                .unstack(level=[1,2]).fillna(0)\n                .stack([1,2]).fillna(0).reset_index())\ndf[\"item_cnt_day\"].clip(0.,20.,inplace=True)","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"bca816bc7371eb360c2b330f3f908b253602ab2e","trusted":true,"collapsed":true},"cell_type":"code","source":"# By Item / Date\nitem = (df.groupby([\"date_block_num\",\"item_id\"])[[\"item_cnt_day\",\"item_price\"]].agg(\n    dict(item_cnt_day= [\"sum\",\"mean\",\"max\",\"std\"],\n         item_price= [\"sum\",\"mean\",\"max\",\"std\"]))).reset_index()\nitem.columns = pd.Index([\"item_\" + e[0] +\"_\"+ e[1] for e in item.columns.tolist()])\ndf = pd.merge(df,item, how=\"left\", left_on = [\"date_block_num\",\"item_id\"],\n        right_on=[\"item_date_block_num_\",\"item_item_id_\"]).drop([\"item_date_block_num_\",\"item_item_id_\"],axis=1)\n\n# By Shop / Date\nshop = (df.groupby([\"date_block_num\",\"shop_id\"])[[\"item_cnt_day\",\"item_price\"]].agg(\n    dict(item_cnt_day= [\"sum\",\"mean\",\"max\",\"std\"],\n         item_price= [\"sum\",\"mean\",\"max\",\"std\"]))).reset_index()\nshop.columns = pd.Index([\"shop_\" + e[0] +\"_\"+ e[1] for e in shop.columns.tolist()])\ndf = pd.merge(df,shop, how=\"left\", left_on = [\"date_block_num\",\"shop_id\"],\n        right_on=[\"shop_date_block_num_\",\"shop_shop_id_\"]).drop([\"shop_date_block_num_\",\"shop_shop_id_\"],axis=1)\ndel item, shop","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56abc1ea18335327090def142b2521fc3d2d0adb"},"cell_type":"code","source":"# Merge and Expand Category Variable\nitems = pd.merge(items, cats, on = \"item_category_id\",how='left')\nitems = (pd.concat([items,items.item_category_name.str.split('-', n=1,expand=True)], axis=1)\n      .rename(columns = {0:\"category1\",1:\"category2\"}))[[\"item_id\",\"category1\",\"category2\"]]\n\n# Encode Russian Strings into categorical interger\nlbl = preprocessing.LabelEncoder()\nfor col in [\"category1\",\"category2\"]:\n    items[col] = lbl.fit_transform(items[col].astype(str))\n\n# Merge Df and Items.. \ndf = pd.merge(df, items,on=\"item_id\",how=\"left\")\n\n# Additional Ideas:\n\"\"\"\nStochastic Gradient Descent\nBatch Normalization\nLess Dropout?\n\"\"\"","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d38b06829950b0a989fa5647605fe08f9c17af3d","trusted":true,"collapsed":true},"cell_type":"code","source":"y_var = df.loc[df.date_block_num != 0,\"item_cnt_day\"].copy()\ndf.date_block_num = df.date_block_num + 1\nn_samples = df[\"shop_id\"].nunique()*df[\"item_id\"].nunique()\ndf = df.drop([\"shop_id\",\"item_id\"],axis=1).set_index(\"date_block_num\")","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"6ddf4edb523e664d780666bff88cd3617ac4aa4d","trusted":true},"cell_type":"code","source":"# Input Output\ny = y_var.values.reshape(y_var.shape[0],1)\nX = df.values.reshape(n_samples*35,1,df.shape[1])\ntesting = X[-n_samples:,:,:] # Test Set\nX = X[:-n_samples,:,:]\nprint(\"X for Submission Shape: \",X.shape)\nprint(\"y Shape: \",y.shape)\nprint(\"X Shape: \",X.shape)\n\n# Validation Set\nval_size = 1\ny_train = y[:-val_size*n_samples,:]\ny_valid = y[-val_size*n_samples:,:]\nX_train = X[:-val_size*n_samples,:,:]\nX_valid = X[-val_size*n_samples:,:,:]\nprint(\"y Train Shape: \",y_train.shape)\nprint(\"X Train Shape: \",X_train.shape)\nprint(\"y Valid Shape: \",y_valid.shape)\nprint(\"X Valid Shape: \",X_valid.shape)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"8999ee2b727d30fffe6690175c4f5f6ace30618f","scrolled":false,"trusted":true},"cell_type":"code","source":"VALID = True\nif VALID is True:\n    inputshape = (X_train.shape[1], X_train.shape[2])\nelse: \n    inputshape = (X.shape[1], X.shape[2])\n\nLSTM_PARAM = {\"batch_size\":512,\n              \"verbose\":1,\n              \"epochs\":3}\n    \nprint(\"Modeling Stage\")\n# Define the model layers\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(200, input_shape=inputshape,return_sequences=True))\n#model_lstm.add(PReLU())\nmodel_lstm.add(BatchNormalization())\nmodel_lstm.add(Dropout(0.4))\n\nmodel_lstm.add(LSTM(64))\nmodel_lstm.add(PReLU())\nmodel_lstm.add(BatchNormalization())\nmodel_lstm.add(Dropout(0.2))\n\n# model_lstm.add(LSTM(64))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(0.2))\n\nmodel_lstm.add(Dense(1))\n\n# model_lstm = Sequential()\n# model_lstm.add(LSTM(512, input_shape=inputshape))\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.2))\n\n# model_lstm.add(Dense(256))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.1))\n\n# model_lstm.add(Dense(256))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.1))\n\n# model_lstm.add(Dense(128))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.05))\n\n# model_lstm.add(Dense(64))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.05))\n\n# model_lstm.add(Dense(32))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.05))\n\n# model_lstm.add(Dense(16))\n# model_lstm.add(PReLU())\n# model_lstm.add(BatchNormalization())\n# model_lstm.add(Dropout(.05))\n\n# model_lstm.add(Dense(1))\n\n# Compile\nopt = optimizers.Adam(lr=0.02)\n#opt = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel_lstm.compile(optimizer=opt, loss='mse', metrics=[\"mse\",root_mean_squared_error])\nprint(model_lstm.summary())\n\n# Optimizer\n\n\n# Train Model\nprint(\"\\nFit Model\")\nmodelstart = time.time()\nif VALID is True:\n    callbacks_list=[EarlyStopping(monitor=\"val_loss\",min_delta=.001, patience=5,mode='auto')]\n    hist = model_lstm.fit(X_train, y_train,\n                          validation_data=(X_valid, y_valid),\n                          callbacks=callbacks_list,\n                          **LSTM_PARAM)\n\n    # Model Evaluation\n    best = np.argmin(hist.history[\"val_loss\"])\n    print(\"Optimal Epoch: \",best+1)\n    print(\"Train Score: {}, Validation Score: {}\".format(hist.history[\"loss\"][best],\n                                                         hist.history[\"val_loss\"][best]))\n\n    plt.plot(hist.history['loss'], label='train')\n    plt.plot(hist.history['val_loss'], label='validation')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Mean Square Error\")\n    plt.legend()\n    plt.show()\n    plt.savefig(\"Train and Validation MSE Progression.png\")\n\nif VALID is False:\n    hist = model_lstm.fit(X,y,**LSTM_PARAM)\n    \n    plt.plot(hist.history['loss'], label='Training Loss')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Mean Square Error\")\n    plt.legend()\n    plt.show()\n    plt.savefig(\"Training Loss Progression.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50c6ce9a676967f0fc19632c21bdae94fae4a1a3","trusted":true},"cell_type":"code","source":"pred = model_lstm.predict(testing)\n\nprint(\"Output Submission\")\nsubmission = pd.DataFrame(pred.clip(0.,20.),columns=['item_cnt_month'])\nsubmission.to_csv(OUT_PATH + 'submission.csv',index_label='ID')\n\nprint(submission.shape)\nprint(submission.head())\nprint(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\nprint(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"f13fb63fcd67420e79e01f447a2148ef1fffca09","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":1}