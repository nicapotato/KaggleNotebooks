{"cells":[{"metadata":{"collapsed":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport time\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\nfrom sklearn import preprocessing","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Thanks You Guillaume Martin for the Awesome Memory Optimizer!\n# https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else: df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df\n\n# Load Files - Thanks Cafeal\n# https://www.kaggle.com/cafeal/lightgbm-trial-public-0-742\ninput_files = os.listdir(\"../input\")\nfor filename in input_files:\n    locals()[filename.rstrip('.csv')] = import_data(f'../input/{filename}')#.sample(5000)\n    print(filename.rstrip('.csv'), \"## Loaded and Optimized ##\\n\")","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"fff39561-fab9-412c-8903-477fc00047ae","_uuid":"6fa702abc8b7817a4fa78087da3ff7f0aa028cfb","trusted":true},"cell_type":"code","source":"traindex = application_train.SK_ID_CURR\ntestdex = application_test.SK_ID_CURR\nprint('Train shape: {} Rows, {} Columns'.format(*application_train.shape))\nprint('Test shape: {} Rows, {} Columns'.format(*application_test.shape))\n\n# Dependent Variable\ny = application_train[\"TARGET\"].values\napplication_train.drop(\"TARGET\",axis=1,inplace= True)\ndf = pd.concat([application_train,application_test],axis=0)\ndel application_train, application_test ; gc.collect();\n\n# Encoder:\ncategorical_columns = [f for f in df.columns if df[f].dtype == 'object']\nlbl = preprocessing.LabelEncoder()\nfor col in categorical_columns:\n    df[col] = lbl.fit_transform(df[col].astype(str))","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"4b48d438-509e-4042-9a42-e131fc644cb2","_uuid":"e0dcc886bddb49bae51fb28cd82e98db10e99cd2","trusted":true},"cell_type":"code","source":"len([x for x in df.columns if x in categorical_columns]) / len(categorical_columns)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"be98f669-7497-4c28-9432-a83d509dc6d6","_uuid":"ff1ed65ec8dd02bb59ad8ba926de1307d9bf6798","trusted":true},"cell_type":"code","source":"# Aggregate Bureau_balance into Balance, and merge that into the Central Dataframe\nagg_bureau_balance = bureau_balance.reset_index().groupby('SK_ID_BUREAU').agg(\n    dict(MONTHS_BALANCE = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         SK_ID_BUREAU = 'count'))\n# Collapse Multi-Index and Preserve Origin Column Name\nagg_bureau_balance.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_bureau_balance.columns.tolist()])\nSTATUS = pd.get_dummies(bureau_balance[[\"SK_ID_BUREAU\",\"STATUS\"]], columns=[\"STATUS\"]).groupby('SK_ID_BUREAU').sum()\n# Float to Interger\nfor col in STATUS.columns: STATUS[col] = STATUS[col].astype(int)\nagg_bureau_balance = pd.merge(agg_bureau_balance,STATUS,on=\"SK_ID_BUREAU\", how= \"left\")\n# Bureau Balance into Bureau Df\nbureau = pd.merge(bureau,agg_bureau_balance, on=\"SK_ID_BUREAU\", how= \"left\")\n# Now Aggregate the Bureau Dataset\nbureau.drop(\"SK_ID_BUREAU\",axis=1,inplace=True)\ncat = [\"CREDIT_ACTIVE\",\"CREDIT_CURRENCY\",\"CREDIT_TYPE\"]\nnotcat = [x for x in bureau.columns if x not in cat + [\"SK_ID_CURR\"]]\n# Bureau Continous Variables\nagg_bureau = bureau.groupby('SK_ID_CURR').agg({k:[\"sum\",\"mean\",\"max\",\"min\",\"std\"] for k in notcat})\nagg_bureau.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_bureau.columns.tolist()])\ndf = pd.merge(df,agg_bureau, on=\"SK_ID_CURR\", how= \"left\")\n# Bureau Categorical Variables\nlbl = preprocessing.LabelEncoder()\nfor col in bureau.select_dtypes(include=['object']).columns: bureau[col] = lbl.fit_transform(bureau[col].astype(str))\nagg_bureau = bureau.groupby('SK_ID_CURR').agg({k: lambda x: x.mode().iloc[0] for k in cat})\nagg_bureau.columns = ['{}_AGGMODE'.format(a) for a in agg_bureau.columns]\ndf = pd.merge(df,agg_bureau, on=\"SK_ID_CURR\", how= \"left\")\ncategorical_columns.extend(agg_bureau.columns)\ndel bureau, agg_bureau_balance, bureau_balance, agg_bureau; gc.collect();","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"96f3f9b9-fa8d-4da3-87dd-ce750f352d40","_uuid":"4fc9d9de6658c4e15cc57a05bec03daa70b9b229","trusted":true},"cell_type":"code","source":"len([x for x in df if x in categorical_columns if x in df.columns]) / len(categorical_columns)","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4df7f820-354c-45f1-bf11-e00e8ed0fa0f","_uuid":"5b0bb99702158b8f6a25974167e8159f036a6cd3","trusted":true},"cell_type":"code","source":"# Aggregate and merge POS_CASH_balance into Central Dataframe\nagg_POS_CASH_balance = POS_CASH_balance.reset_index().groupby('SK_ID_CURR').agg(\n    dict(MONTHS_BALANCE = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         CNT_INSTALMENT = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         CNT_INSTALMENT_FUTURE = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         SK_DPD = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         SK_DPD_DEF = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n         SK_ID_CURR = 'count'))\nagg_POS_CASH_balance.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_POS_CASH_balance.columns.tolist()])\nNAME_CONTRACT_STATUS = pd.get_dummies(POS_CASH_balance[[\"SK_ID_CURR\",\"NAME_CONTRACT_STATUS\"]], columns=[\"NAME_CONTRACT_STATUS\"]).groupby('SK_ID_CURR').sum()\nfor col in NAME_CONTRACT_STATUS.columns: NAME_CONTRACT_STATUS[col] = NAME_CONTRACT_STATUS[col].astype(int)\nagg_POS_CASH_balance = pd.merge(agg_POS_CASH_balance,NAME_CONTRACT_STATUS, left_on=\"SK_ID_CURR\", right_on=\"SK_ID_CURR\", how= \"left\")\ndf = pd.merge(df,agg_POS_CASH_balance, left_on=\"SK_ID_CURR\", right_on=\"SK_ID_CURR\", how= \"left\")\ndel agg_POS_CASH_balance,NAME_CONTRACT_STATUS,POS_CASH_balance; gc.collect();","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"beb932b9-ca6b-469c-900e-31e809025f9b","_uuid":"42ffa7f97da2ea8ad2066c9fd6ee9ee4b658f899","trusted":true},"cell_type":"code","source":"# Aggregate and merge POS_CASH_balance into Central Dataframe\n# Distinguish Column Types\ncontinuous_var = [x for x in previous_application.select_dtypes(include=['float16','float32','int8','int16','int32']).columns\n                  if x not in [\"SK_ID_PREV\",\"SK_ID_CURR\", \"SELLERPLACE_AREA\",\"NFLAG_LAST_APPL_IN_DAY\",\"NFLAG_INSURED_ON_APPROVAL\"]]\ncategorical_var = [x for x in previous_application.columns if x not in continuous_var + ['SK_ID_CURR']]\n                   \n # Bureau Categorical Variables\nlbl = preprocessing.LabelEncoder()\nfor col in categorical_var: previous_application[col] = lbl.fit_transform(previous_application[col].astype(str))\nagg_previous_application = previous_application.groupby('SK_ID_CURR').agg({k: lambda x: x.mode().iloc[0] for k in categorical_var})\nagg_previous_application.columns = ['{}_AGGMODE'.format(a) for a in agg_previous_application.columns]\ndf = pd.merge(df,agg_previous_application, on=\"SK_ID_CURR\", how= \"left\")\ncategorical_columns.extend(agg_previous_application.columns)\nprint(agg_previous_application.columns)\ndel agg_previous_application; gc.collect();\n                   \n# Continous Variables\nagg_previous_application = previous_application.groupby('SK_ID_CURR').agg({k:[\"sum\",\"mean\",\"max\",\"min\",\"std\"] for k in continuous_var})\nagg_previous_application.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_previous_application.columns.tolist()])\ndf = pd.merge(df,agg_previous_application, left_on=\"SK_ID_CURR\", right_on=\"SK_ID_CURR\", how= \"left\")\ndel previous_application,agg_previous_application; gc.collect();","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"b81f285b-7c4a-4732-bf71-fa2dd21e31ba","_uuid":"7633c3b1874b184a4bec63f9d98c9ec529e6223d","trusted":true},"cell_type":"code","source":"len([x for x in df.columns if x in categorical_columns]) / len(categorical_columns)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"09e58df4-e8d5-4af8-898a-26247b9be177","_uuid":"63b181c9ef05b800721358abc4723b978de6c90a","trusted":true},"cell_type":"code","source":"\n\n# Encoder:\n# categorical_columns2 = df.select_dtypes(include=['object']).columns:\n# lbl = preprocessing.LabelEncoder()\n# for col in categorical_columns2:\n#     df[col] = lbl.fit_transform(df[col].astype(str))\n# #categorical_columns.extend(categorical_columns2)\n\n# Optimize\ndf = reduce_mem_usage(df)\n# Set Index (out of the way)\ndf.set_index(\"SK_ID_CURR\",inplace=True)\n\n# Final Train and Test Set\nX = df.loc[traindex,:]\ntest = df.loc[testdex,:]\n\ny = pd.Series(y)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndel df; gc.collect();","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"e49c1961-12b2-41e9-bd44-c226f4a42b27","_uuid":"8c33e1743b1cfa74850586ead4a86139c443eed9","trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=23)\n        \nclf = LGBMClassifier(\n    n_estimators=1000,\n    learning_rate=0.1,\n    num_leaves=100,\n    colsample_bytree=.8,\n    subsample=.9,\n    max_depth=-1,\n    reg_alpha=.1,\n    reg_lambda=.1,\n    min_split_gain=.01,\n    min_child_weight=2\n)\n\nclf.fit(X_train,y_train, eval_set= [(X_train,y_train), (X_valid,y_valid)],\n        eval_metric='auc', verbose=50, early_stopping_rounds=150)\n\n\nprint(\"Model Evaluation Stage\")\nprint('Valid AUC score %.6f' % roc_auc_score(y_valid, clf.predict_proba(X_valid, num_iteration=clf.best_iteration_)[:, 1]))\npred = clf.predict_proba(test, num_iteration=clf.best_iteration_)[:, 1]\nsklearn_lgbm_sub = pd.DataFrame(pred,columns=[\"TARGET\"],index=testdex)\nsklearn_lgbm_sub.to_csv(\"sklearn_lgbm_sub.csv\",index=True)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"4a68b0dc-c173-4cb2-887c-39a4f2be364d","_uuid":"356d8b5af7c4cb7bd56e2f7f7542fbab9b4080dd","scrolled":true,"trusted":true},"cell_type":"code","source":"lgbm_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n#     'max_depth': 9,\n#     #'num_leaves': 500,\n#     'learning_rate': 0.01,\n#     'feature_fraction': 0.80,\n#     'bagging_fraction': 0.80,\n#     'bagging_freq': 5,\n#     'max_bin':300,\n#     #'verbose': 0,\n#     #'num_threads': 1,\n#     'lambda_l2': 1.5,\n#     #'min_gain_to_split': 0,\n#     'is_unbalance': True\n    #'scale_pos_weight':0.15\n}  \n\n# LGBM Dataset Formatting \nlgtrain = lgb.Dataset(X_train, y_train, categorical_feature = categorical_columns)\nlgvalid = lgb.Dataset(X_valid, y_valid, categorical_feature = categorical_columns)\n\nmodelstart = time.time()\nlgb_clf = lgb.train(\n    lgbm_params,\n    lgtrain,\n    num_boost_round=1000,\n    valid_sets=[lgtrain, lgvalid],\n    valid_names=['train','valid'],\n    early_stopping_rounds=500,\n    verbose_eval=150\n)\nprint(\"Model Evaluation Stage\")\n#print('Valid AUC score %.6f' % roc_auc_score(y_valid, lgb_clf.predict(X_valid)))\nlgbmpred = lgb_clf.predict(test)\nlgbm_sub = pd.DataFrame(lgbmpred,columns=[\"TARGET\"],index=testdex)\nlgbm_sub.to_csv(\"lgbm_sub.csv\",index=True)\nprint(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n# del lgvalid, lgtrain; gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9100cf7a-7b44-4f31-b8cf-ddec0ca03b32","_uuid":"05e06d0afa5c0c4c1826646fdde6e94a5a423e0a","trusted":true,"collapsed":true},"cell_type":"code","source":"folds = KFold(n_splits=2, shuffle=True, random_state=546789)\noof_preds = np.zeros(X.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nlgbm_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'is_unbalance': True,\n    'max_depth': 7,\n#     \"num_leaves\":30,\n#     \"colsample_bytree\":.8,\n#     'feature_fraction': 0.7,\n#     'bagging_fraction': 0.8,\n#     'bagging_freq': 5,\n#     \"subsample\":.9,\n    'lambda_l2': 20,\n#     \"min_split_gain\":.01,\n#     \"min_child_weight\":2\n}  \n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n    X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n    X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n\n    # LGBM Dataset Formatting \n    lgtrain = lgb.Dataset(X_train, y_train, categorical_feature = categorical_columns)\n    lgvalid = lgb.Dataset(X_valid, y_valid, categorical_feature = categorical_columns)\n\n    modelstart = time.time()\n    lgb_clf = lgb.train(\n        lgbm_params,\n        lgtrain,\n        num_boost_round=2000,\n        valid_sets=[lgtrain, lgvalid],\n        valid_names=['train','valid'],\n        early_stopping_rounds=300,\n        verbose_eval=100\n    )\n    oof_preds[val_idx] = lgb_clf.predict(X_valid)\n    sub_preds += lgb_clf.predict(test) / int(folds.n_splits)\n    \n    print('\\nFold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(y_valid, oof_preds[val_idx])))\n    del X_train, y_train, X_valid, y_valid #,lgb_clf\n    gc.collect()\n    \n    \n    \nprint('\\nFull AUC score %.6f' % roc_auc_score(y, oof_preds)) \nlgbm_sub_oof = pd.DataFrame(sub_preds,columns=[\"TARGET\"],index=testdex)\nlgbm_sub_oof.to_csv(\"lgbm_sub_oof.csv\",index=True,float_format='%.8f')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0aa1240-6124-4875-bbde-3f11328490a9","_uuid":"9496d54ba73ca560b1778ecd585c5ca6a1ba851b","trusted":true,"collapsed":true},"cell_type":"code","source":"# Viz\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Feature Importance Plot\nf, ax = plt.subplots(figsize=[7,10])\nlgb.plot_importance(lgb_clf, max_num_features=50, ax=ax)\nplt.title(\"Light GBM Feature Importance\")\nplt.savefig('feature_import.png')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2064b720-7101-4419-9752-fd1bd81964c1","_uuid":"6d32f48244e12ecdac8debeb9741f333cc55ab85","trusted":true},"cell_type":"code","source":"#     fold_importance_df = pd.DataFrame()\n#     fold_importance_df[\"feature\"] = X.columns\n#     fold_importance_df[\"importance\"] = clf.feature_importances_\n#     fold_importance_df[\"fold\"] = n_fold + 1\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n#     del clf, trn_x, trn_y, val_x, val_y\n#     gc.collect()\n    \n# print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))   \n\n# test['TARGET'] = sub_preds\n\n# test[['SK_ID_CURR', 'TARGET']].to_csv('first_submission.csv', index=False, float_format='%.8f')\n\n# # Plot feature importances\n# cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n#     by=\"importance\", ascending=False)[:50].index\n\n# best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\n# plt.figure(figsize=(8,10))\n# sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n# plt.title('LightGBM Features (avg over folds)')\n# plt.tight_layout()\n# plt.savefig('lgbm_importances.png')\n\n# # Plot ROC curves\n# plt.figure(figsize=(6,6))\n# scores = [] \n# for n_fold, (_, val_idx) in enumerate(folds.split(data)):  \n#     # Plot the roc curve\n#     fpr, tpr, thresholds = roc_curve(y.iloc[val_idx], oof_preds[val_idx])\n#     score = roc_auc_score(y.iloc[val_idx], oof_preds[val_idx])\n#     scores.append(score)\n#     plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n\n# plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n# fpr, tpr, thresholds = roc_curve(y, oof_preds)\n# score = roc_auc_score(y, oof_preds)\n# plt.plot(fpr, tpr, color='b',\n#          label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n#          lw=2, alpha=.8)\n\n# plt.xlim([-0.05, 1.05])\n# plt.ylim([-0.05, 1.05])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('LightGBM ROC Curve')\n# plt.legend(loc=\"lower right\")\n# plt.tight_layout()\n\n# plt.savefig('roc_curve.png')","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}