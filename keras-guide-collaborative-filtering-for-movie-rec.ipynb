{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Keras Guide Collaborative Filtering for Movie Recommendations\n\nhttps://keras.io/examples/structured_data/collaborative_filtering_movielens/"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nTitle: Collaborative Filtering for Movie Recommendations\nAuthor: [Siddhartha Banerjee](https://twitter.com/sidd2006)\nDate created: 2020/05/24\nLast modified: 2020/05/24\nDescription: Recommending movies using a model trained on Movielens dataset.\n\"\"\"\n\"\"\"\n## Introduction\nThis example demonstrates\n[Collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)\nusing the [Movielens dataset](https://www.kaggle.com/c/movielens-100k)\nto recommend movies to users.\nThe MovieLens ratings dataset lists the ratings given by a set of users to a set of movies.\nOur goal is to be able to predict ratings for movies a user has not yet watched.\nThe movies with the highest predicted ratings can then be recommended to the user.\nThe steps in the model are as follows:\n1. Map user ID to a \"user vector\" via an embedding matrix\n2. Map movie ID to a \"movie vector\" via an embedding matrix\n3. Compute the dot product between the user vector and movie vector, to obtain\nthe a match score between the user and the movie (predicted rating).\n4. Train the embeddings via gradient descent using all known user-movie pairs.\n**References:**\n- [Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/371920.372071)\n- [Neural Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/3038912.3052569)\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom zipfile import ZipFile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n## First, load the data and apply preprocessing\n\"\"\"\n\n# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n# Use the ratings.csv file\nmovielens_data_file_url = (\n    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n)\nmovielens_zipped_file = keras.utils.get_file(\n    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n)\nkeras_datasets_path = Path(movielens_zipped_file).parents[0]\nmovielens_dir = keras_datasets_path / \"ml-latest-small\"\n\n# Only extract the data the first time the script is run.\nif not movielens_dir.exists():\n    with ZipFile(movielens_zipped_file, \"r\") as zip:\n        # Extract files\n        print(\"Extracting all the files now...\")\n        zip.extractall(path=keras_datasets_path)\n        print(\"Done!\")\n\nratings_file = movielens_dir / \"ratings.csv\"\ndf = pd.read_csv(ratings_file)\n\ndisplay(df.sample(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nFirst, need to perform some preprocessing to encode users and movies as integer indices.\n\"\"\"\nuser_ids = df[\"userId\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuserencoded2user = {i: x for i, x in enumerate(user_ids)}\nmovie_ids = df[\"movieId\"].unique().tolist()\nmovie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\nmovie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\ndf[\"user\"] = df[\"userId\"].map(user2user_encoded)\ndf[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n\nnum_users = len(user2user_encoded)\nnum_movies = len(movie_encoded2movie)\ndf[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n# min and max ratings will be used to normalize the ratings later\nmin_rating = min(df[\"rating\"])\nmax_rating = max(df[\"rating\"])\n\nprint(\n    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n        num_users, num_movies, min_rating, max_rating\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n## Prepare training and validation data\n\"\"\"\ndf = df.sample(frac=1, random_state=42)\nx = df[[\"user\", \"movie\"]].values\n# Normalize the targets between 0 and 1. Makes it easy to train.\ny = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n# Assuming training on 90% of the data and validating on 10%.\ntrain_indices = int(0.9 * df.shape[0])\nx_train, x_val, y_train, y_val = (\n    x[:train_indices],\n    x[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n## Create the model\nWe embed both users and movies in to 50-dimensional vectors.\nThe model computes a match score between user and movie embeddings via a dot product,\nand adds a per-movie and per-user bias. The match score is scaled to the `[0, 1]`\ninterval via a sigmoid (since our ratings are normalized to this range).\n\"\"\"\nEMBEDDING_SIZE = 50\n\n\nclass RecommenderNet(keras.Model):\n    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n        super(RecommenderNet, self).__init__(**kwargs)\n        self.num_users = num_users\n        self.num_movies = num_movies\n        self.embedding_size = embedding_size\n        self.user_embedding = layers.Embedding(\n            num_users,\n            embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),\n        )\n        self.user_bias = layers.Embedding(num_users, 1)\n        self.movie_embedding = layers.Embedding(\n            num_movies,\n            embedding_size,\n            embeddings_initializer=\"he_normal\",\n            embeddings_regularizer=keras.regularizers.l2(1e-6),\n        )\n        self.movie_bias = layers.Embedding(num_movies, 1)\n\n    def call(self, inputs):\n        user_vector = self.user_embedding(inputs[:, 0])\n        user_bias = self.user_bias(inputs[:, 0])\n        movie_vector = self.movie_embedding(inputs[:, 1])\n        movie_bias = self.movie_bias(inputs[:, 1])\n        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n        # Add all the components (including bias)\n        x = dot_user_movie + user_bias + movie_bias\n        # The sigmoid activation forces the rating to between 0 and 1\n        return tf.nn.sigmoid(x)\n\n\nmodel = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\nmodel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"\n## Train the model based on the data split\n\"\"\"\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=64,\n    epochs=5,\n    verbose=1,\n    validation_data=(x_val, y_val),\n)\n\n\"\"\"\n## Plot training and validation loss\n\"\"\"\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n## Show top 10 movie recommendations to a user\n\"\"\"\n\ndef recommend_movie(user_id, df, movie_df, movie2movie_encoded, user2user_encoded):\n    # Let us get a user and see the top recommendations.\n    movies_watched_by_user = df[df.userId == user_id]\n    movies_not_watched = movie_df[\n        ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n    ][\"movieId\"]\n    movies_not_watched = list(\n        set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n    )\n    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n    user_encoder = user2user_encoded.get(user_id)\n    user_movie_array = np.hstack(\n        ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n    )\n    ratings = model.predict(user_movie_array).flatten()\n    top_ratings_indices = ratings.argsort()[-10:][::-1]\n    recommended_movie_ids = [\n        movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n    ]\n\n    print(\"Showing recommendations for user: {}\".format(user_id))\n    print(\"====\" * 9)\n    print(\"Movies with high ratings from user\")\n    print(\"----\" * 8)\n    top_movies_user = (\n        movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n        .head(5)\n        .movieId.values\n    )\n    movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n    for row in movie_df_rows.itertuples():\n        print(row.title, \":\", row.genres)\n\n    print(\"----\" * 8)\n    print(\"Top 10 movie recommendations\")\n    print(\"----\" * 8)\n    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n    for row in recommended_movies.itertuples():\n        print(row.title, \":\", row.genres)\n        \n    print(\"\\n\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n\nfor _ in range(10):\n    user_id = df.userId.sample(1).iloc[0]\n    recommend_movie(user_id, df, movie_df, movie2movie_encoded, user2user_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}