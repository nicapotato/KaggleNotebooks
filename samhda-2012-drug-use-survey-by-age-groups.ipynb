{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Substance Abuse and Mental Health Data Archive (SAMHDA)\n## 2012 Survey on Drug Use by Age Groups\n_By Nick Brooks, November 2020_\n\n**Resources:**\n- https://fivethirtyeight.com/features/how-baby-boomers-get-high/\n- https://github.com/fivethirtyeight/data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport math\nimport itertools\nfrom wordcloud import WordCloud\nfrom itertools import combinations\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nSIA = SentimentIntensityAnalyzer()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nsns.set_style(\"whitegrid\")\nnotebookstart = time.time()\npd.options.display.max_colwidth = 500\npd.options.display.max_rows = 999\npd.options.display.width = 300\npd.options.display.max_columns = 100","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def big_bar_cloud(plot_df, plt_set, x_var, columns, figsize, custom_palette = sns.color_palette(\"Paired\")):\n    \"\"\"\n    Iteratively Plot BarPlots\n    \"\"\"\n    palette = itertools.cycle(custom_palette)\n    rows = math.ceil(len(plt_set)/columns)\n    n_plots = rows*columns\n    f,ax = plt.subplots(rows, columns, figsize = figsize)\n    for i in range(0,n_plots):\n        ax = plt.subplot(rows, columns, i+1)\n        if i < len(plt_set):\n            col = plt_set[i]\n            sns.barplot(data=df, x=x_var, y=col, ax=ax, color=next(palette), alpha=.8)\n            ax.set_title(\"{} by {}\".format(col, x_var))\n        else:\n            ax.axis('off')\n    plt.tight_layout(pad=2)\n    \n    \n    \ndef rank_correlations(df, figsize=(12,20), n_charts = 18, polyorder = 2, custom_palette = sns.color_palette(\"Paired\", 5)):\n    # Rank Correlations\n    palette = itertools.cycle(custom_palette)\n    continuous_rankedcorr = (df\n                             .corr()\n                             .unstack()\n                             .drop_duplicates().reset_index())\n    continuous_rankedcorr.columns = [\"f1\",\"f2\",\"Correlation Coefficient\"]\n    continuous_rankedcorr['abs_cor'] = abs(continuous_rankedcorr[\"Correlation Coefficient\"])\n    continuous_rankedcorr.sort_values(by='abs_cor', ascending=False, inplace=True)\n\n    # Plot Top Correlations\n    top_corr = [(x,y,cor) for x,y,cor in list(continuous_rankedcorr.iloc[:, :3].values) if x != y]\n    f, axes = plt.subplots(int(n_charts/3),3, figsize=figsize, sharex=False, sharey=False)\n    row = 0\n    col = 0\n    for (x,y, cor) in top_corr[:n_charts]:\n        if col == 3:\n            col = 0\n            row += 1\n        g = sns.regplot(x=x, y=y, data=df, order=polyorder, ax = axes[row,col], color=next(palette))\n        axes[row,col].set_title('{} and {}'.format(x, y))\n        axes[row,col].text(0.18, 0.93,\"Cor Coef: {:.2f}\".format(cor),\n                           ha='center', va='center', transform=axes[row,col].transAxes)\n        col += 1\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n    \n# Data Exploration\ndef custom_describe(df, value_count_n = 5):\n    \"\"\"\n    Custom Describe Function - More Tailored to categorical type variables..\n    \"\"\"\n    unique_count = []\n    for x in df.columns:\n        unique_values_count = df[x].nunique()\n        value_count = df[x].value_counts().iloc[:5]\n\n        value_count_list = []\n        value_count_string = []\n        \n        for vc_i in range(0,value_count_n):\n            value_count_string += [\"ValCount {}\".format(vc_i+1),\n                                   \"Occ\"]\n            if vc_i <= unique_values_count - 1:\n                value_count_list.append(value_count.index[vc_i])\n                value_count_list.append(value_count.iloc[vc_i])\n            else:\n                value_count_list.append(np.nan)\n                value_count_list.append(np.nan)\n        \n        unique_count.append([x,\n                             unique_values_count,\n                             df[x].isnull().sum(),\n                             df[x].dtypes] + value_count_list)\n        \n    print(\"Dataframe Dimension: {} Rows, {} Columns\".format(*df.shape))\n    return pd.DataFrame(unique_count,\n            columns=[\"Column\",\"Unique\",\"Missing\",\"dtype\"\n                    ] + value_count_string\n                       ).set_index(\"Column\")\n\nprint(\"Helper Functions Ready\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [\n    'age'\n]\n\n\ncontinuous_cols = [\n    'alcohol-use',\n    'alcohol-frequency',\n    'marijuana-use',\n    'marijuana-frequency',\n    'cocaine-use',\n    'cocaine-frequency',\n    'crack-use',\n    'crack-frequency',\n    'heroin-use',\n    'heroin-frequency',\n    'hallucinogen-use',\n    'hallucinogen-frequency',\n    'inhalant-use',\n    'inhalant-frequency',\n    'pain-releiver-use',\n    'pain-releiver-frequency',\n    'oxycontin-use',\n    'oxycontin-frequency',\n    'tranquilizer-use',\n    'tranquilizer-frequency',\n    'stimulant-use',\n    'stimulant-frequency',\n    'meth-use',\n    'meth-frequency',\n    'sedative-use',\n    'sedative-frequency',\n    'n'\n]\n\ndf = pd.read_csv(\"/kaggle/input/fivethirtyeight-drug-use-by-age-dataset/drug-use-by-age.csv\")\nprint(\"DF Shape: {} Rows, {} Columns\".format(*df.shape))\n\n# Data Cleaning\nfor col in continuous_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.head(30))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Categorical Variables\")\ndisplay(custom_describe(df[categorical_cols]))\nprint(\"Continuous Variables\")\ndisplay(df[continuous_cols].describe().T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_bar_cloud(plot_df=df, plt_set=continuous_cols, x_var='age', columns=2, figsize=[20,32])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Correlation Matrix\nf, ax = plt.subplots(figsize=[14,12])\nax = sns.heatmap(df[continuous_cols].corr(), \n                 annot=True, fmt=\".1f\",\n                 vmin=-1, vmax=1,\n                 cbar_kws={'label': 'Correlation Coefficient'})\nax.set_title(\"Continuous Variable Correlation Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rank_correlations(df = df.loc[:,continuous_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Script Complete - Runtime: {:.2f} Minutes\".format((time.time() - notebookstart) / 60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}